{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIAV0EsmiLFyF8kSsnoOgj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isj0/DeepLearning/blob/main/Test_Run_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9nof8VEli9Ut"
      },
      "outputs": [],
      "source": [
        "# 0. Import required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
        "from sklearn.ensemble import VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the NSL-KDD dataset from HuggingFace\n",
        "ds = load_dataset(\"Mireu-Lab/NSL-KDD\")"
      ],
      "metadata": {
        "id": "0PyA-BZIjE97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2c3522-1e0b-4c03-ba2b-d646d34385bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. convert HuggingFace datasets to pandas data frames\n",
        "train = ds['train']\n",
        "test = ds['test']\n",
        "# Convert to DataFrame\n",
        "train_df = pd.DataFrame(train)\n",
        "test_df = pd.DataFrame(test)\n",
        "\n",
        "# shape of training data\n",
        "print(\"Training set shape:\", train_df.shape)\n",
        "\n",
        "# shape of testing data\n",
        "print(\"Testing set shape:\", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHKtRLt6qcay",
        "outputId": "40bef6fc-1ac7-40b2-9a5c-4c5745762d7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (151165, 42)\n",
            "Testing set shape: (34394, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Check initial class distribution\n",
        "\n",
        "print(\"Unique classes (train):\", train_df['class'].unique())\n",
        "print(\"Unique classes (test):\", test_df['class'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kneqWGn_jkm1",
        "outputId": "fabfb4d6-c90c-47e9-854c-b5843d798663"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes (train): ['normal' 'anomaly']\n",
            "Unique classes (test): ['anomaly' 'normal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Remove duplicate rows\n",
        "# ================================================================\n",
        "print(\"Duplicates before removal (train):\", train_df.duplicated().sum())\n",
        "print(\"Duplicates before removal (test):\", test_df.duplicated().sum())\n",
        "\n",
        "train_df = train_df.drop_duplicates()\n",
        "test_df = test_df.drop_duplicates()\n",
        "\n",
        "print(\"Duplicates after removal (train):\", train_df.duplicated().sum())\n",
        "print(\"Duplicates after removal (test):\", test_df.duplicated().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8TGmES8k2Ff",
        "outputId": "09662dca-5029-4fd2-fb92-c7ec5b10075e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicates before removal (train): 25201\n",
            "Duplicates before removal (test): 11853\n",
            "Duplicates after removal (train): 0\n",
            "Duplicates after removal (test): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Convert class column to binary (0 = normal, 1 = attack)\n",
        "# ================================================================\n",
        "def convert_class(label):\n",
        "    return 0 if label == 'normal' else 1\n",
        "\n",
        "train_df['class'] = train_df['class'].apply(convert_class)\n",
        "test_df['class'] = test_df['class'].apply(convert_class)\n",
        "\n",
        "print(train_df['class'].value_counts())\n",
        "print(test_df['class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymhANwMOlHlG",
        "outputId": "ad51c9b9-d145-4d43-b662-56996dfafe89"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class\n",
            "0    67343\n",
            "1    58621\n",
            "Name: count, dtype: int64\n",
            "class\n",
            "1    12830\n",
            "0     9711\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. One-Hot Encode categorical columns\n",
        "# ================================================================\n",
        "categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "\n",
        "train_encoded = pd.get_dummies(train_df, columns=categorical_columns)\n",
        "test_encoded = pd.get_dummies(test_df, columns=categorical_columns)\n",
        "\n",
        "# Align test to training columns\n",
        "# (Test may not contain some categories present in training)\n",
        "test_encoded = test_encoded.reindex(columns=train_encoded.columns, fill_value=0)\n"
      ],
      "metadata": {
        "id": "CYZ3n8M5lKm2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Split into X (features) and y (labels)\n",
        "# ================================================================\n",
        "X_train = train_encoded.drop('class', axis=1)\n",
        "y_train = train_encoded['class']\n",
        "\n",
        "X_test = test_encoded.drop('class', axis=1)\n",
        "y_test = test_encoded['class']"
      ],
      "metadata": {
        "id": "aclOWJ-DlOPF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train NA count:\", X_train.isna().sum().sum())\n",
        "print(\"Test NA count:\", X_test.isna().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRGzXkRRqLkP",
        "outputId": "bf1dcae3-77a3-4776-97ab-e987929c5fd8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train NA count: 0\n",
            "Test NA count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Scale features\n",
        "# ================================================================\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "D3LPop2ulQlu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Apply PCA (retain 95% variance)\n",
        "# ================================================================\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "print(\"PCA components:\", X_train_pca.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8siqA0rqlSsF",
        "outputId": "f7ea4c33-c4da-4093-8467-9a3e92f2e2ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA components: 89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Sanity checks and validation\n",
        "\n",
        "print(\"Columns aligned:\", X_train.columns.equals(X_test.columns))\n",
        "\n",
        "total_var = pca.explained_variance_ratio_.sum()\n",
        "print(f\"PCA explained variance: {total_var:.4f}\")\n",
        "print(f\"PCA n_components: {X_train_pca.shape[1]}\")\n",
        "\n",
        "attack_ratio_train = y_train.mean()\n",
        "attack_ratio_test = y_test.mean()\n",
        "print(f\"Attack ratio (train): {attack_ratio_train:.4f}\")\n",
        "print(f\"Attack ratio (test): {attack_ratio_test:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELZsbDkQqPxu",
        "outputId": "210e34b0-5a77-4e7a-f4c5-39220b540222"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns aligned: True\n",
            "PCA explained variance: 0.9526\n",
            "PCA n_components: 89\n",
            "Attack ratio (train): 0.4654\n",
            "Attack ratio (test): 0.5692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds)\n",
        "    rec = recall_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "\n",
        "    return acc, prec, rec, f1, cm"
      ],
      "metadata": {
        "id": "uSwaNSuKMyZ4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"SVM (RBF)\": SVC(kernel='rbf', gamma='scale', random_state=42),\n",
        "}"
      ],
      "metadata": {
        "id": "1qENZl9EM4Lk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    print(\"\\n=======================================\")\n",
        "    print(f\"Model: {name}\")\n",
        "\n",
        "    acc, prec, rec, f1, cm = evaluate(model, X_train_pca, X_test_pca, y_train, y_test)\n",
        "\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1 Score:  {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHfWCjCsNA8J",
        "outputId": "68081efe-dff5-4efa-adff-1af994d84717"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=======================================\n",
            "Model: Decision Tree\n",
            "Accuracy:  0.7922\n",
            "Precision: 0.9305\n",
            "Recall:    0.6862\n",
            "F1 Score:  0.7899\n",
            "Confusion Matrix:\n",
            "[[9053  658]\n",
            " [4026 8804]]\n",
            "\n",
            "=======================================\n",
            "Model: Random Forest\n",
            "Accuracy:  0.7968\n",
            "Precision: 0.9695\n",
            "Recall:    0.6639\n",
            "F1 Score:  0.7881\n",
            "Confusion Matrix:\n",
            "[[9443  268]\n",
            " [4312 8518]]\n",
            "\n",
            "=======================================\n",
            "Model: SVM (RBF)\n",
            "Accuracy:  0.8021\n",
            "Precision: 0.9265\n",
            "Recall:    0.7086\n",
            "F1 Score:  0.8030\n",
            "Confusion Matrix:\n",
            "[[8990  721]\n",
            " [3739 9091]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Baseline Models with Class Weighting / Imbalance Handling\n",
        "# ================================================================\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Define models\n",
        "# DecisionTree, RandomForest, and SVM support 'class_weight' directly\n",
        "# MLP does not support class_weight or sample_weight in scikit-learn (solver='adam')\n",
        "# ------------------------------\n",
        "models_weighted = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
        "    \"SVM (RBF)\": SVC(kernel='rbf', gamma='scale', class_weight='balanced', random_state=42),\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Evaluation function\n",
        "# ------------------------------\n",
        "def evaluate_weighted(model, X_train, X_test, y_train, y_test, sample_weight=None, model_name=None):\n",
        "    \"\"\"\n",
        "    Train the model on training data and evaluate on test data.\n",
        "\n",
        "    Parameters:\n",
        "    - model: classifier\n",
        "    - X_train, y_train: training data\n",
        "    - X_test, y_test: test data\n",
        "    - sample_weight: optional weights (used for MLP workaround)\n",
        "    - model_name: used to skip sample_weight for MLP\n",
        "\n",
        "    Returns:\n",
        "    - acc, prec, rec, f1: metrics\n",
        "    - cm: confusion matrix\n",
        "    \"\"\"\n",
        "    # DT, RF, SVM can use sample_weight\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weight)\n",
        "\n",
        "    # Predict on test set\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Compute metrics\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds)\n",
        "    rec = recall_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "\n",
        "    return acc, prec, rec, f1, cm\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Train & evaluate each model\n",
        "# ------------------------------\n",
        "for name, model in models_weighted.items():\n",
        "    print(\"\\n=======================================\")\n",
        "    print(f\"Model: {name}\")\n",
        "\n",
        "    sample_weight = None\n",
        "    # Train and evaluate\n",
        "    acc, prec, rec, f1, cm = evaluate_weighted(\n",
        "        model, X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "        sample_weight=sample_weight, model_name=name\n",
        "    )\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1 Score:  {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6BlJbf3DOBw",
        "outputId": "86ad330d-7e08-44bd-d2cf-e6dad4ea474d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=======================================\n",
            "Model: Decision Tree\n",
            "Accuracy:  0.8093\n",
            "Precision: 0.9584\n",
            "Recall:    0.6952\n",
            "F1 Score:  0.8058\n",
            "Confusion Matrix:\n",
            "[[9324  387]\n",
            " [3911 8919]]\n",
            "\n",
            "=======================================\n",
            "Model: Random Forest\n",
            "Accuracy:  0.7757\n",
            "Precision: 0.9682\n",
            "Recall:    0.6266\n",
            "F1 Score:  0.7608\n",
            "Confusion Matrix:\n",
            "[[9447  264]\n",
            " [4791 8039]]\n",
            "\n",
            "=======================================\n",
            "Model: SVM (RBF)\n",
            "Accuracy:  0.7890\n",
            "Precision: 0.9245\n",
            "Recall:    0.6852\n",
            "F1 Score:  0.7871\n",
            "Confusion Matrix:\n",
            "[[8993  718]\n",
            " [4039 8791]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Train Isolation Forest (unsupervised)\n",
        "# ================================================================\n",
        "\n",
        "# Step 1: Initialize model\n",
        "# - n_estimators: number of trees\n",
        "# - max_samples: number of samples used to build each tree\n",
        "# - contamination: expected fraction of anomalies in data\n",
        "# - random_state: for reproducibility\n",
        "iso_forest = IsolationForest(\n",
        "    n_estimators=100,      # 100 trees is a good beginner-friendly default\n",
        "    max_samples='auto',    # automatically set to min(256, n_samples)\n",
        "    contamination=0.1,     # assume ~10% attacks; adjust if needed\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Step 2: Train model\n",
        "# We use only X_train features (unsupervised â€” no labels needed)\n",
        "iso_forest.fit(X_train_pca)\n",
        "\n",
        "# Step 3: Predict on test set\n",
        "# Returns -1 (anomaly) or 1 (normal)\n",
        "y_pred_if = iso_forest.predict(X_test_pca)\n",
        "\n",
        "# Step 4: Convert predictions to 0 (normal) / 1 (attack)\n",
        "y_pred_if_binary = np.where(y_pred_if == -1, 1, 0)\n",
        "\n",
        "# Step 5: Evaluate performance\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_if_binary)\n",
        "prec = precision_score(y_test, y_pred_if_binary)\n",
        "rec = recall_score(y_test, y_pred_if_binary)\n",
        "f1 = f1_score(y_test, y_pred_if_binary)\n",
        "cm = confusion_matrix(y_test, y_pred_if_binary)\n",
        "\n",
        "# Step 6: Print results\n",
        "print(\"\\n=======================================\")\n",
        "print(\"Isolation Forest (unsupervised) Results\")\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall:    {rec:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhTCLp24F9Xy",
        "outputId": "97e2fcdd-fc31-4033-ba21-cb31cbb99ed2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=======================================\n",
            "Isolation Forest (unsupervised) Results\n",
            "Accuracy:  0.5583\n",
            "Precision: 0.9597\n",
            "Recall:    0.2337\n",
            "F1 Score:  0.3759\n",
            "Confusion Matrix:\n",
            "[[9585  126]\n",
            " [9831 2999]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# Ensemble Models\n",
        "# ---------------------------------------------\n",
        "\n",
        "ensemble_models = {\n",
        "    \"Soft Voting\": VotingClassifier(\n",
        "        estimators=[\n",
        "            (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
        "            (\"rf\", RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "            (\"svm\", SVC(kernel='rbf', probability=True, random_state=42))\n",
        "        ],\n",
        "        voting='soft'\n",
        "    ),\n",
        "\n",
        "    \"Bagging (Decision Tree)\": BaggingClassifier(\n",
        "        estimator=DecisionTreeClassifier(),\n",
        "        n_estimators=50,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"AdaBoost\": AdaBoostClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
        "        n_estimators=150,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n"
      ],
      "metadata": {
        "id": "7HKjrSeif6tP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# Train and evaluate ensemble models\n",
        "# ---------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"  Ensemble Model Results\")\n",
        "print(\"==============================\")\n",
        "\n",
        "for name, model in ensemble_models.items():\n",
        "    print(\"\\n=======================================\")\n",
        "    print(f\"Model: {name}\")\n",
        "\n",
        "    acc, prec, rec, f1, cm = evaluate(model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
        "\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1 Score:  {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_Xe-xFRf7ak",
        "outputId": "a42c2138-472e-4c62-e8ef-04065b5acf66"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "  Ensemble Model Results\n",
            "==============================\n",
            "\n",
            "=======================================\n",
            "Model: Soft Voting\n",
            "Accuracy:  0.7899\n",
            "Precision: 0.9683\n",
            "Recall:    0.6523\n",
            "F1 Score:  0.7795\n",
            "Confusion Matrix:\n",
            "[[9437  274]\n",
            " [4461 8369]]\n",
            "\n",
            "=======================================\n",
            "Model: Bagging (Decision Tree)\n",
            "Accuracy:  0.8059\n",
            "Precision: 0.9690\n",
            "Recall:    0.6807\n",
            "F1 Score:  0.7997\n",
            "Confusion Matrix:\n",
            "[[9432  279]\n",
            " [4097 8733]]\n",
            "\n",
            "=======================================\n",
            "Model: AdaBoost\n",
            "Accuracy:  0.7827\n",
            "Precision: 0.9580\n",
            "Recall:    0.6465\n",
            "F1 Score:  0.7720\n",
            "Confusion Matrix:\n",
            "[[9347  364]\n",
            " [4535 8295]]\n",
            "\n",
            "=======================================\n",
            "Model: Gradient Boosting\n",
            "Accuracy:  0.7943\n",
            "Precision: 0.9707\n",
            "Recall:    0.6585\n",
            "F1 Score:  0.7847\n",
            "Confusion Matrix:\n",
            "[[9456  255]\n",
            " [4382 8448]]\n"
          ]
        }
      ]
    }
  ]
}